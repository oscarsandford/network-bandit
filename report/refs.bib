%% References here. No fewer than 10 references.

@inproceedings{p2p_def,
  author    = {Schollmeier, R.},
  booktitle = {Proceedings First International Conference on Peer-to-Peer Computing},
  title     = {A definition of peer-to-peer networking for the classification of peer-to-peer architectures and applications},
  year      = {2001},
  volume    = {},
  number    = {},
  pages     = {101-102},
  doi       = {10.1109/P2P.2001.990434}
}

@inbook{mab_algos,
  author    = {Vermorel,Joannès and Mohri,Mehryar},
  year      = {2005},
  title     = {Multi-armed Bandit Algorithms and Empirical Evaluation},
  series    = {Machine Learning: ECML 2005},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  edition   = {1ère éd},
  pages     = {437-448},
  keywords  = {Applied sciences; Artificial intelligence; Bandit Problem; Computer science; control theory; systems; Content Distribution Network; Empirical Evaluation; Exact sciences and technology; Greedy Strategy; Learning and adaptive systems; Reward Distribution},
  isbn      = {0302-9743},
  language  = {English}
}

@article{qos_selection_mab,
  author  = {Modi, Navikkumar and Mary, Philippe and Moy, Christophe},
  journal = {IEEE Transactions on Cognitive Communications and Networking},
  title   = {QoS Driven Channel Selection Algorithm for Cognitive Radio Network: Multi-User Multi-Armed Bandit Approach},
  year    = {2017},
  volume  = {3},
  number  = {1},
  pages   = {49-66},
  doi     = {10.1109/TCCN.2017.2675901}
}

@article{muMAB_wireless,
  author         = {Boldrini, Stefano and De Nardis, Luca and Caso, Giuseppe and Le, Mai T. P. and Fiorina, Jocelyn and Di Benedetto, Maria-Gabriella},
  title          = {muMAB: A Multi-Armed Bandit Model for Wireless Network Selection},
  journal        = {Algorithms},
  volume         = {11},
  year           = {2018},
  number         = {2},
  article-number = {13},
  url            = {https://www.mdpi.com/1999-4893/11/2/13},
  issn           = {1999-4893},
  abstract       = {Multi-armed bandit (MAB) models are a viable approach to describe the problem of best wireless network selection by a multi-Radio Access Technology (multi-RAT) device, with the goal of maximizing the quality perceived by the final user. The classical MAB model does not allow, however, to properly describe the problem of wireless network selection by a multi-RAT device, in which a device typically performs a set of measurements in order to collect information on available networks, before a selection takes place. The MAB model foresees in fact only one possible action for the player, which is the selection of one among different arms at each time step; existing arm selection algorithms thus mainly differ in the rule according to which a specific arm is selected. This work proposes a new MAB model, named measure-use-MAB (muMAB), aiming at providing a higher flexibility, and thus a better accuracy in describing the network selection problem. The muMAB model extends the classical MAB model in a twofold manner; first, it foresees two different actions: to measure and to use; second, it allows actions to span over multiple time steps. Two new algorithms designed to take advantage of the higher flexibility provided by the muMAB model are also introduced. The first one, referred to as measure-use-UCB1 (muUCB1) is derived from the well known UCB1 algorithm, while the second one, referred to as Measure with Logarithmic Interval (MLI), is appositely designed for the new model so to take advantage of the new measure action, while aggressively using the best arm. The new algorithms are compared against existing ones from the literature in the context of the muMAB model, by means of computer simulations using both synthetic and captured data. Results show that the performance of the algorithms heavily depends on the Probability Density Function (PDF) of the reward received on each arm, with different algorithms leading to the best performance depending on the PDF. Results highlight, however, that as the ratio between the time required for using an arm and the time required to measure increases, the proposed algorithms guarantee the best performance, with muUCB1 emerging as the best candidate when the arms are characterized by similar mean rewards, and MLI prevailing when an arm is significantly more rewarding than others. This calls thus for the introduction of an adaptive approach capable of adjusting the behavior of the algorithm or of switching algorithm altogether, depending on the acquired knowledge on the PDF of the reward on each arm.},
  doi            = {10.3390/a11020013}
}

@article{multiuser_mab,
  author  = {Avner, Orly and Mannor, Shie},
  journal = {IEEE/ACM Transactions on Networking},
  title   = {Multi-User Communication Networks: A Coordinated Multi-Armed Bandit Approach},
  year    = {2019},
  volume  = {27},
  number  = {6},
  pages   = {2192-2207},
  doi     = {10.1109/TNET.2019.2935043}
}

@article{mab_wireless_scheduling_survey,
  author  = {Li, Feng and Yu, Dongxiao and Yang, Huan and Yu, Jiguo and Karl, Holger and Cheng, Xiuzhen},
  journal = {IEEE Wireless Communications},
  title   = {Multi-Armed-Bandit-Based Spectrum Scheduling Algorithms in Wireless Networks: A Survey},
  year    = {2020},
  volume  = {27},
  number  = {1},
  pages   = {24-30},
  doi     = {10.1109/MWC.001.1900280}
}

@inproceedings{mab_dist_exploration,
  author    = {Hillel, Eshcar and Karnin, Zohar and Koren, Tomer and Lempel, Ronny and Somekh, Oren},
  title     = {Distributed Exploration in Multi-Armed Bandits},
  year      = {2013},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 1},
  pages     = {854-862},
  numpages  = {9},
  location  = {Lake Tahoe, Nevada},
  series    = {NIPS'13}
}

@inproceedings{link_adaptation_in_cellular_networks,
  author    = {Saxena, Vidit and Jald\'{e}n, Joakim and Gonzalez, Joseph E. and Bengtsson, Mats and Tullberg, Hugo and Stoica, Ion},
  title     = {Contextual Multi-Armed Bandits for Link Adaptation in Cellular Networks},
  year      = {2019},
  isbn      = {9781450368728},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3341216.3342212},
  doi       = {10.1145/3341216.3342212},
  abstract  = {Cellular networks dynamically adjust the transmission parameters for a wireless link in response to its time-varying channel state. This is known as link adaptation, where the typical goal is to maximize the link throughput. State-of-the-art outer loop link adaptation (OLLA) selects the optimal transmission parameters based on an approximate, offline, model of the wireless link. Further, OLLA refines the offline model by dynamically compensating any deviations from the observed link performance. However, in practice, OLLA suffers from slow convergence and a sub-optimal link throughput. In this paper, we propose a link adaptation approach that overcomes the shortcomings of OLLA through a novel learning scheme. Our approach relies on contextual multi-armed bandits (MAB), where the context vector is composed of the instantaneous wireless channel state along with side information about the link. For a given context, our approach learns the success probability for each of the available transmission parameters, which is then exploited to select the throughput-maximizing parameters. Through numerical experiments, we show that our approach converges faster than OLLA and achieves a higher steady-state link throughput. For frequent and infrequent channel reports respectively, our scheme outperforms OLLA by 15% and 25% in terms of the steady-state link throughput.},
  booktitle = {Proceedings of the 2019 Workshop on Network Meets AI &amp; ML},
  pages     = {44-49},
  numpages  = {6},
  keywords  = {cellular networks, artificial neural networks, outer loop link adaptation, contextual multi-armed bandits},
  location  = {Beijing, China},
  series    = {NetAI'19}
}

@misc{mab_algos_1,
  doi       = {10.48550/ARXIV.1402.6028},
  url       = {https://arxiv.org/abs/1402.6028},
  author    = {Kuleshov, Volodymyr and Precup, Doina},
  keywords  = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Algorithms for multi-armed bandit problems},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{gossip_based_distrivuted_stochastic,
  author    = {Sz\"{o}r\'{e}nyi, Bal\'{a}zs and Busa-Fekete, R\'{o}bert and Heged\"{u}s, Istv\'{a}n and Orm\'{a}ndi, R\'{o}bert and Jelasity, M\'{a}rk and K\'{e}gl, Bal\'{a}zs},
  title     = {Gossip-Based Distributed Stochastic Bandit Algorithms},
  year      = {2013},
  publisher = {JMLR.org},
  abstract  = {The multi-armed bandit problem has attracted remarkable attention in the machine learning community and many efficient algorithms have been proposed to handle the so-called exploitation-exploration dilemma in various bandit setups. At the same time, significantly less effort has been devoted to adapting bandit algorithms to particular architectures, such as sensor networks, multicore machines, or peer-to-peer (P2P) environments, which could potentially speed up their convergence. Our goal is to adapt stochastic bandit algorithms to P2P networks. In our setup, the same set of arms is available in each peer. In every iteration each peer can pull one arm independently of the other peers, and then some limited communication is possible with a few random other peers. As our main result, we show that our adaptation achieves a linear speedup in terms of the number of peers participating in the network. More precisely, we show that the probability of playing a suboptimal arm at a peer in iteration t = Ω(log N) is proportional to 1/(Nt) where N denotes the number of peers. The theoretical results are supported by simulation experiments showing that our algorithm scales gracefully with the size of network.},
  booktitle = {Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28},
  pages     = {III-19-III-27},
  location  = {Atlanta, GA, USA},
  series    = {ICML'13}
}

@inproceedings{p2p_offloading_with_delayed_feedback,
  author    = {Yang, Miao and Zhu, Hongbin and Wang, Haifeng and Koucheryavy, Yevgeni and Samouylov, Konstantin and Qian, Hua},
  booktitle = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Peer To Peer Offloading With Delayed Feedback: An Adversary Bandit Approach},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {5035-5039},
  doi       = {10.1109/ICASSP40776.2020.9053680}
}

@inproceedings{p2p_net_sender_scheduling,
  author    = {Si, Pengbo and Yu, F. Richard and Ji, Hong and Leung, Victor C. M.},
  booktitle = {IEEE GLOBECOM 2008 - 2008 IEEE Global Telecommunications Conference},
  title     = {Distributed Sender Scheduling for Multimedia Transmission in Wireless Peer-to-Peer Networks},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {1-5},
  doi       = {10.1109/GLOCOM.2008.ECP.992}
}

@article{dist_clustering_p2p,
  title={Distributed Clustering of Linear Bandits in Peer to Peer Networks},
  author={Nathaniel Korda and Bal{\'a}zs Sz{\"o}r{\'e}nyi and Shuai Li},
  journal={ArXiv},
  year={2016},
  volume={abs/1604.07706}
}


@article{gpu_eng,
	abstract = {Graphics processing units (GPUs) are extensively used as accelerators across multiple application domains, ranging from general purpose applications to neural networks, and cryptocurrency mining. The initial utilization paradigm for GPUs was one application accessing all the resources of the GPU. In recent years, time sharing is broadly used among applications of a GPU, nevertheless, spatial sharing is not fully explored. When concurrent applications share the computational resources of a GPU, performance can be improved by eliminating idle resources. Additionally, the incorporation of GPUs in embedded and mobile devices increases the demand for power efficient computation due to battery limitations. In this article, we present an allocation methodology for streaming multiprocessors (SMs). The presented methodology works for two concurrent applications on a GPU and determines an allocation scheme that will provide power efficient application execution, combined with improved GPU performance. Experimental results show that the developed methodology yields higher throughput while achieving improved power efficiency, compared to other SM power-aware and performance-aware policies. If the presented methodology is adopted, it will lead to higher performance of applications that are concurrently executing on a GPU. This will lead to a faster and more efficient acceleration of execution, even for devices with restrained energy sources.},
	article-number = {1451},
	author = {Tasoulas, Zois-Gerasimos and Anagnostopoulos, Iraklis},
	doi = {10.3390/electronics8121451},
	issn = {2079-9292},
	journal = {Electronics},
	number = {12},
	title = {Improving GPU Performance with a Power-Aware Streaming Multiprocessor Allocation Methodology},
	url = {https://www.mdpi.com/2079-9292/8/12/1451},
	volume = {8},
	year = {2019},
	Bdsk-Url-1 = {https://www.mdpi.com/2079-9292/8/12/1451},
	Bdsk-Url-2 = {https://doi.org/10.3390/electronics8121451}
}
