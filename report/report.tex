%%%%%%%% ICML 2020 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2020} with \usepackage[nohyperref]{icml2020} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2021}
\usepackage[accepted]{icml2021}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2020}

\usepackage{times}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{comment}
\newcommand{\nop}[1]{}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Multi-Armed Bandits for Optimizing New Peers in Peer-to-Peer Networks}

\begin{document}

\twocolumn[
\icmltitle{Multi-Armed Bandits for Optimizing New Peers in Peer-to-Peer Networks}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2020
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
% \icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Oscar Sandford}{to}
\icmlauthor{Shawn Nettleton}{to}
\end{icmlauthorlist}

\icmlaffiliation{to}{Department of Computer Science, University of Victoria, Victoria, Canada}

\icmlcorrespondingauthor{Oscar Sandford}{oscarsandford@uvic.ca}
\icmlcorrespondingauthor{Shawn Nettleton}{shawnnettleton@uvic.ca}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Write this last (fewer than 300 words). The completed document should be 5-9 pages.
\end{abstract}

%-------------------------------------------------------------------------------
% Problem, why it is important/interesting, and the plan for the approach.
\section{Introduction}
Peer-to-peer computer networks create a unique environment for content distribution wherein the integrity of the system is not compromised by the failure of 
a single, centralized node in the network. According to \cite{p2p_def}, true peer-to-peer systems require peers to be mutually directly accessible (without 
intermediate entities), as well as the network state or quality of service being preserved in the advent of a peer being removed from the network, for any 
reason.

The requirements for peer-to-peer networks in different application domains vary. However, new peers that are directly accessing the server for the first time 
have no information on the network state. New peers therefore cannot be held accountable to preserve the network state and its content if other nodes disconnect. 
It is essential that this new peer is fed the relevant data as fast as possible in order to fulfill both the requirements of a true peer-to-peer environment, as 
well as any necessary quality of service targets. With the added volatility of a dynamic network setting, the rate at which a new peer can be brought "up to speed" 
becomes far more crucial.

In this study, we abstract the new peer scenario described above as a reinforcement learning problem with multi-armed bandits. The multi-armed bandit problem involves 
$k$ slot machines (slot machines are sometimes called one-armed bandits) which pay out reward values according to an internal distribution, of which the agent cannot 
know. The goal is to pick a strategy to learn which arms pay out the most in order to to maximize total reward over a set number of rounds \cite{mab_algos}. 

Various algorithms to solve the multi-armed bandit problem are considered, and a select few are implemented in order to evaluate their efficacy against this problem. 
Related literature is surveyed in order to compare our work with solutions to similar problems and verify the validity of our results. Formulation of this challenge 
as a reinforcement learning problem precedes an explanation of the approach and a discussion of the results. First, a survey of related work concerning the application 
of multi-armed bandits to computer networking problems.

%-------------------------------------------------------------------------
% Example of related work section. Discuss relevant literature.
\section{Related Work}

% \subsection{Bandit Algorithms}
% Maybe we talk more about specific algorithms in the approach section?


% \subsection{Computer Networks}
Multi-armed bandits serve as a useful abstraction for optimization problems that require decision making with reward outcomes that are initially unknown. In a study 
concerning cognitive radio networks \cite{qos_selection_mab}, secondary user (SU) nodes select a single channel for information exchange at one time, with no knowledge 
about channel quality or availability. The authors use a variation on the upper confidence bound (UCB) algorithm, namely QoS-UCB. Their scenario is called "restless", 
meaning that the states of the arms can fluctuate over time, affecting their internal distrubtions and the resulting payouts.

The task of wireless network selection, with the goal of maximizing perceived quality for the end user, is handled by extending the bandit model to be more flexible 
\cite{muMAB_wireless}. In this formulation, the agent can take one of two actions (which can span multiple time steps): measure or use. The difference is that 
measurement allows only evaluation, whereas using adds exploitation. Measuring takes less time than using, which can span a set number of time steps. Results showed 
that the choice of algorithm depended on the payout distributions. Conservative UCB1 is useful when arm rewards are similar, MLI when one arm is clearly better. 
More aggressive algorithms like POKER can lead to low regret but high variability, and are therefore less reliable \cite{muMAB_wireless}.

Anver and Mannor share methods for multiple multi-armed bandit agents, coordinating with each other and learning stochastic network conditions, which may vary between 
users \cite{multiuser_mab}. Their problem formulation is similar to our intentions, but with the agent transmitting instead of receiving. Further, they bound their rewards 
on the interval $[0,1]$. The problem with this reward formulation when it comes to receiving is that, while outward transmission speed or success may be measureably bounded, 
reception rate is not necessarily bounded. In fact, there may be conditions when the end receiver does not have the resources to unpack the transmission packages in time, 
and will become congested. This paper uses techniques to deal with collisions when two or more users transmit in a single channel \cite{multiuser_mab}. In our problem, we 
are only operating with unicast in a channel selected by the requesting peer. A last thing of note is Anver and Mannor's use of UCB in the channel ranking part of their 
algorithm selection.

Another paper surveys resource scheduling with multi-armed bandits in wireless networks \cite{mab_wireless_scheduling_survey}. They mention that $\varepsilon$-greedy, an 
algorithm that balancing exploration and exploitation, has shortcomings in its "pure" randomness, and does not take into account confidence intervals on the reward estimates 
of each arm. UCB exploits this, and also tapers off exploration over time. The authors make the distinction between single- and multi-player multi-armed bandits (SMAB and 
MMAB), where the former involves a single agent operating the bandit selection mechanism. SMAB have applications in our single peer leeching scenario, as well as centralized 
network algorithms. MMAB often involve distributed selection that sacrifices independence for synchronization overhead \cite{mab_wireless_scheduling_survey}.

%-------------------------------------------------------------------------
\section{Problem Formulation}

Consider the setting of a peer-to-peer network wherein a new peer joins with the intent to be brought "up to speed" with the rest of the network as soon as 
possible (i.e. download all the data in the network from other peers). However, the new peer does not know the network speeds of its seeds, just how much data 
it receives over time when it chooses a peer and receives data from them for one time step. The reward is how many bytes received in that time slot. We will 
assume that data packets are UDP datagrams.

We want to be careful about defining the reward, because we want the agent to choose the peer that is transmitting the fastest. However, consider that network 
speeds may change, and the optimal seed to leech from will not always be the best. We call this a "restless" scenario.


%-------------------------------------------------------------------------
% Algorithms we will use and develop (e.g. eps-greedy, UCB, and more). Implementation details, pseudocode here.
\section{Approach}
% Various algorithms will be considered, starting with epsilon-greedy and UCB (upper confidence bound). More complex bandit algorithms are considered as well.



%----------------------------------------------------------------------------------
% Use of implementation to produce results. Graphs here.
\section{Results}
Text here.

% What results we expect? Include assumptions and proof sketches.
\subsection{Theoretical Results} 
Text here.

% Details on experiments and test results.
\subsection{Experiment Results} 
Text here.


%-------------------------------------------------------------------------------
% Discussion on results. Pros and cons of suggested solution compared with existing solutions. 
\section{Discussion}

Text here.

%-------------------------------------------------------------------------------
% What we learned. Future work, takeaways.
\section{Conclusion and Future Research}

Text here.


\bibliography{refs}
\bibliographystyle{icml2021}

\end{document}